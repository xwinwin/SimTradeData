"""
SimTradeData ç®€åŒ–é›†æˆæµ‹è¯•

éªŒè¯æ ¸å¿ƒæ¨¡å—çš„åŸºæœ¬é›†æˆåŠŸèƒ½ã€‚
"""

import logging
import tempfile
from pathlib import Path

import pytest

from simtradedata.api import APIRouter
from simtradedata.config import Config
from simtradedata.database import DatabaseManager
from simtradedata.performance import QueryOptimizer
from simtradedata.performance.cache_manager import CacheManager

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class TestPTradeCacheIntegration:
    """SimTradeData é›†æˆæµ‹è¯•"""

    @pytest.fixture
    def temp_db_path(self):
        """ä¸´æ—¶æ•°æ®åº“è·¯å¾„"""
        with tempfile.NamedTemporaryFile(suffix=".db", delete=False) as f:
            yield f.name
        # æ¸…ç†
        Path(f.name).unlink(missing_ok=True)

    @pytest.fixture
    def config(self, temp_db_path):
        """æµ‹è¯•é…ç½®"""
        config = Config()
        config.set("database.path", temp_db_path)
        config.set("cache.enable", True)
        config.set("cache.ttl", 300)
        config.set("system_monitor.enable_monitoring", False)
        config.set("health_checker.enable_monitoring", False)
        config.set("ops_tools.enable_auto_maintenance", False)
        config.set("performance_monitor.enable_monitoring", False)
        return config

    @pytest.fixture
    def db_manager(self, config):
        """æ•°æ®åº“ç®¡ç†å™¨"""
        db_path = config.get("database.path")
        db_manager = DatabaseManager(db_path)
        # åˆå§‹åŒ–è¿æ¥ï¼ˆé€šè¿‡è®¿é—®connectionå±æ€§ï¼‰
        _ = db_manager.connection
        yield db_manager
        # æ¸…ç†è¿æ¥
        if hasattr(db_manager, "_local") and hasattr(db_manager._local, "connection"):
            if db_manager._local.connection:
                db_manager._local.connection.close()

    def test_database_and_cache_integration(self, config, db_manager):
        """æµ‹è¯•æ•°æ®åº“å’Œç¼“å­˜é›†æˆ"""
        logger.info("ğŸ§ª æµ‹è¯•æ•°æ®åº“å’Œç¼“å­˜é›†æˆ...")

        # 1. æµ‹è¯•æ•°æ®åº“è¿æ¥
        # é€šè¿‡æ‰§è¡Œç®€å•æŸ¥è¯¢æµ‹è¯•è¿æ¥
        result = db_manager.fetchone("SELECT 1 as test")
        assert result is not None
        assert result["test"] == 1

        # 2. æµ‹è¯•ç¼“å­˜ç®¡ç†å™¨
        cache_manager = CacheManager(config)

        # æµ‹è¯•ç¼“å­˜æ“ä½œ
        test_data = {"symbol": "000001.SZ", "price": 10.5}
        cache_manager.set("test_key", test_data, "test_type")
        cached_data = cache_manager.get("test_key", "test_type")
        assert cached_data == test_data

        # 3. æµ‹è¯•APIè·¯ç”±å™¨
        api_router = APIRouter(db_manager, config)

        # æµ‹è¯•è·¯ç”±å™¨ç»Ÿè®¡
        stats = api_router.get_api_stats()
        assert "api_name" in stats or "error" not in stats

        logger.info("âœ… æ•°æ®åº“å’Œç¼“å­˜é›†æˆæµ‹è¯•é€šè¿‡")

    def test_performance_modules_integration(self, config, db_manager):
        """æµ‹è¯•æ€§èƒ½æ¨¡å—é›†æˆ"""
        logger.info("ğŸ§ª æµ‹è¯•æ€§èƒ½æ¨¡å—é›†æˆ...")

        # 1. æµ‹è¯•æŸ¥è¯¢ä¼˜åŒ–å™¨
        optimizer = QueryOptimizer(db_manager, config)

        # æµ‹è¯•æŸ¥è¯¢ä¼˜åŒ–
        sql = "SELECT 1 as test_value"
        result = optimizer.execute_with_cache(sql, ())
        assert result is not None

        # æµ‹è¯•ç¼“å­˜ç»Ÿè®¡
        cache_stats = optimizer.get_cache_stats()
        assert "hits" in cache_stats
        assert "misses" in cache_stats

        logger.info("âœ… æ€§èƒ½æ¨¡å—é›†æˆæµ‹è¯•é€šè¿‡")

    @pytest.mark.skip(reason="ç›‘æ§æ¨¡å—å°šæœªå®ç°")
    def test_monitoring_modules_integration(self, config, db_manager):
        """æµ‹è¯•ç›‘æ§æ¨¡å—é›†æˆ"""
        logger.info("ğŸ§ª æµ‹è¯•ç›‘æ§æ¨¡å—é›†æˆ...")

        # ç›‘æ§æ¨¡å—å¾…å®ç°
        logger.info("âœ… ç›‘æ§æ¨¡å—é›†æˆæµ‹è¯•è·³è¿‡ï¼ˆå¾…å®ç°ï¼‰")

    def test_data_workflow_integration(self, config, db_manager):
        """æµ‹è¯•æ•°æ®å·¥ä½œæµé›†æˆ"""
        logger.info("ğŸ§ª æµ‹è¯•æ•°æ®å·¥ä½œæµé›†æˆ...")

        # 1. åˆå§‹åŒ–ç»„ä»¶
        cache_manager = CacheManager(config)
        APIRouter(db_manager, config)

        # 2. æµ‹è¯•æ•°æ®å­˜å‚¨å’Œæ£€ç´¢æµç¨‹
        # åˆ›å»ºæµ‹è¯•è¡¨
        db_manager.execute(
            """
            CREATE TABLE IF NOT EXISTS test_stocks (
                symbol TEXT,
                trade_date TEXT,
                close REAL,
                volume INTEGER,
                PRIMARY KEY (symbol, trade_date)
            )
        """
        )

        # æ’å…¥æµ‹è¯•æ•°æ®
        test_data = [
            ("000001.SZ", "2024-01-20", 10.5, 1000000),
            ("000002.SZ", "2024-01-20", 25.8, 800000),
        ]

        for data in test_data:
            db_manager.execute(
                "INSERT OR REPLACE INTO test_stocks (symbol, trade_date, close, volume) VALUES (?, ?, ?, ?)",
                data,
            )

        # 3. æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½
        # ç›´æ¥æ•°æ®åº“æŸ¥è¯¢
        result = db_manager.fetchall(
            "SELECT * FROM test_stocks WHERE symbol = ?", ("000001.SZ",)
        )
        assert len(result) == 1
        assert result[0]["close"] == 10.5

        # 4. æµ‹è¯•ç¼“å­˜åŠŸèƒ½
        # ç¼“å­˜æŸ¥è¯¢ç»“æœ
        cache_key = "test_stocks_000001.SZ"
        cache_manager.set(cache_key, result, "query_result")

        # ä»ç¼“å­˜è·å–
        cached_result = cache_manager.get(cache_key, "query_result")
        assert cached_result == result

        # 5. æµ‹è¯•æŸ¥è¯¢ä¼˜åŒ–å™¨
        optimizer = QueryOptimizer(db_manager, config)

        # ä½¿ç”¨ä¼˜åŒ–å™¨æŸ¥è¯¢ï¼ˆä¼šè‡ªåŠ¨ç¼“å­˜ï¼‰
        optimized_result = optimizer.execute_with_cache(
            "SELECT * FROM test_stocks WHERE symbol = ?", ("000002.SZ",)
        )
        assert len(optimized_result) == 1
        assert optimized_result[0]["close"] == 25.8

        # ç¬¬äºŒæ¬¡æŸ¥è¯¢åº”è¯¥ä»ç¼“å­˜è·å–
        cached_optimized_result = optimizer.execute_with_cache(
            "SELECT * FROM test_stocks WHERE symbol = ?", ("000002.SZ",)
        )
        assert cached_optimized_result == optimized_result

        # éªŒè¯ç¼“å­˜ç»Ÿè®¡
        cache_stats = optimizer.get_cache_stats()
        assert cache_stats["hits"] > 0

        logger.info("âœ… æ•°æ®å·¥ä½œæµé›†æˆæµ‹è¯•é€šè¿‡")

    def test_error_handling_integration(self, config, db_manager):
        """æµ‹è¯•é”™è¯¯å¤„ç†é›†æˆ"""
        logger.info("ğŸ§ª æµ‹è¯•é”™è¯¯å¤„ç†é›†æˆ...")

        # 1. æµ‹è¯•æ•°æ®åº“é”™è¯¯å¤„ç†
        try:
            # æ‰§è¡Œæ— æ•ˆSQL
            db_manager.execute("INVALID SQL STATEMENT")
        except Exception as e:
            # åº”è¯¥æ•è·å¹¶å¤„ç†é”™è¯¯
            assert "syntax error" in str(e).lower() or "near" in str(e).lower()

        # 2. æµ‹è¯•ç¼“å­˜é”™è¯¯å¤„ç†
        cache_manager = CacheManager(config)

        # æµ‹è¯•è·å–ä¸å­˜åœ¨çš„ç¼“å­˜
        result = cache_manager.get("non_existent_key", "test_type")
        assert result is None

        # 3. æµ‹è¯•æŸ¥è¯¢ä¼˜åŒ–å™¨é”™è¯¯å¤„ç†
        optimizer = QueryOptimizer(db_manager, config)

        try:
            # æ‰§è¡Œæ— æ•ˆæŸ¥è¯¢
            optimizer.execute_with_cache("INVALID QUERY", ())
        except Exception:
            # åº”è¯¥ä¼˜é›…åœ°å¤„ç†é”™è¯¯
            pass

        # ä¼˜åŒ–å™¨åº”è¯¥ä»ç„¶å¯ç”¨
        cache_stats = optimizer.get_cache_stats()
        assert isinstance(cache_stats, dict)

        # 4. æµ‹è¯•å¥åº·æ£€æŸ¥é”™è¯¯æ¢å¤ (è·³è¿‡ï¼Œå¾…å®ç°)
        # health_checker = HealthChecker(db_manager, config)
        # health = health_checker.get_overall_health()
        # assert "overall_status" in health

        logger.info("âœ… é”™è¯¯å¤„ç†é›†æˆæµ‹è¯•é€šè¿‡")


def test_simtradedata_integration():
    """SimTradeData é›†æˆæµ‹è¯•å…¥å£"""
    logger.info("ğŸš€ å¼€å§‹SimTradeDataé›†æˆæµ‹è¯•...")

    # è¿™ä¸ªæµ‹è¯•ä¼šè¢«pytestè‡ªåŠ¨å‘ç°å’Œè¿è¡Œ
    # ä¸»è¦ç”¨äºéªŒè¯æ ¸å¿ƒç»„ä»¶èƒ½å¤Ÿæ­£ç¡®åä½œ

    logger.info("ğŸ‰ SimTradeDataé›†æˆæµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    # è¿è¡Œé›†æˆæµ‹è¯•
    test_simtradedata_integration()

    # è¿è¡Œpytestæµ‹è¯•
    pytest.main([__file__, "-v"])
